---
title: "Introduction to Tidyverse and Tidy Data"
author: "Bryan Blanc"
date: "Updated as of `r strftime(Sys.Date(),'%B %d, %Y')`"
output: html_document
---

[Back to overview](../index.html)

## Introduction

The [Tidyverse](https://www.tidyverse.org/) is a 'universe' of packages designed for data science with R. They are all built with an underlying design philosophy and grammar based on the [concept of 'tidy' data](https://vita.had.co.nz/papers/tidy-data.pdf). This session will discuss the tidy data concept and its main package implementations. For me, the tidy data concept influences not just the work I do in R but how I structure spreadsheets and datasets in general, and I have found it to generally result in cleaner data analyses.[Tidyverse packages](https://www.tidyverse.org/packages/) are among the most widely used R packages, and greatly improve upon implementations of basic operations in base R. 

__Acknowledgement:__ This module heavily draws upon Hadley Wickham's (the progenitor of the Tidyverse) book (available for free online), [R for Data Science](https://r4ds.had.co.nz/), including text, pictures, and code directly copied from that book and slightly modified to suit a shorter narrative. Printed copies are available generally wherever you get your books. It is recommended that you read this book for a deeper understanding of the topics contained hereien -- only basic concepts are able to be covered within the time available. 

## A Note on Packages

For those that don't remember what packages are in R -- packages are collections of functions developed with a specific purpose in mind; typically a particular topic, data analysis method, or type of data is the focus of a package. Packages include the functions that comprise them as well as documentation, sample datasets for examples, and 'vignettes', which are example implementations of the code interspersed with narrative. Depending on how well the package has been documented, there may be more or less of these supplementary items. The most useful packages in R are typically those that are well documented. 

There are thousands of R packages, and because of the open source nature of R, anyone can develop a package and post it online. The two main places to get packages are CRAN (Comprehensive R Archive Network) and GitHub. For packages to be uploaded to CRAN, they must meet a minimum standard of documentation and unit testing of code, to ensure some minimum quality of the packages. Packages on GitHub have no standard -- they are hosted by individuals. That said, there is information in the GitHub READMEs about how well the code has been unit tested, and packages are typically only hosted on GitHub in the development phase. If you want the most 'bleeding edge' version of a package (maybe some new features in development are really helpful!), go to GitHub, but if you want the most stable version, go to CRAN. 

A helpful place to start if you have a goal in mind for your R code but you don't know which packages can help is the [CRAN Task View Page](https://cran.r-project.org/web/views/). It is a well maintained list of package topics, including some narrative description of what packages do what within each topic. For example, we might want to check out the [Spatial task view](https://cran.r-project.org/web/views/Spatial.html). There we can see the many packages developed with spatial analysis in mind. 

Another place to go is Google ðŸ¤“ -- there is a widespread (and well documented) R community on GitHub, StackOverflow, and various R blogs that can help put you on the right path. Chances are someone has had the same question as you (typically many someones), and if they haven't then you might have a package to develop on your hands...


## Tidyverse Packages

As mentioned above, the Tidyverse consists of a collection of R packages -- several of the key packages are highlighted below. 

* [ggplot2](https://ggplot2.tidyverse.org), for data visualisation.
* [dplyr](https://dplyr.tidyverse.org), for data manipulation.
* [tidyr](https://tidyr.tidyverse.org), for data tidying.
* [readr](https://readr.tidyverse.org), for data import.
* [purrr](https://purrr.tidyverse.org), for functional programming.
* [tibble](https://tibble.tidyverse.org), for tibbles, a modern re-imagining of data frames.
* [stringr](https://github.com/tidyverse/stringr), for character strings.
* [forcats](https://github.com/hadley/forcats), for factors.

Conveniently, Hadley and RStudio created a [`tidyverse`](https://tidyverse.tidyverse.org/) package, which with a single installation command (`install.packages(tidyverse)`) will install the above packages, and with a single library command (`library(tidyverse)`) will load those packages into your environment. 

You also get a condensed summary of conflicts with other packages you have loaded:

```{r example, warning=FALSE}
library(tidyverse)
```

You can see conflicts created later with `tidyverse_conflicts()`:

```{r conflicts}
library(MASS)
tidyverse_conflicts()
detach("package:MASS", unload=TRUE)
```

As well as the core tidyverse, installing this package also installs a selection of other packages that you're likely to use frequently, but probably not in every analysis. This includes packages for:

*   Working with specific types of vectors:

    * [hms](https://github.com/rstats-db/hms), for times.
    * [lubridate](https://github.com/tidyverse/lubridate), for date/times.
    
*   Importing other types of data:

    * [feather](https://github.com/wesm/feather), for sharing with Python and other languages.
    * [haven](https://github.com/tidyverse/haven), for SPSS, SAS and Stata files.
    * [httr](https://github.com/r-lib/httr), for web apis.
    * [jsonlite](https://github.com/jeroen/jsonlite) for JSON.
    * [readxl](https://github.com/tidyverse/readxl), for `.xls` and `.xlsx` files.
    * [rvest](https://github.com/tidyverse/rvest), for web scraping.
    * [xml2](https://github.com/r-lib/xml2), for XML.

*   Modelling

    * [modelr](https://github.com/tidyverse/modelr), for modelling within a pipeline
    * [broom](https://github.com/tidymodels/broom), for turning models into 
      tidy data

And you can check that all tidyverse packages are up-to-date with `tidyverse_update()`:

```{r update, eval = FALSE}
tidyverse_update()
#> The following packages are out of date:
#>  * broom (0.4.0 -> 0.4.1)
#>  * DBI   (0.4.1 -> 0.5)
#>  * Rcpp  (0.12.6 -> 0.12.7)
#> Update now?
#> 
#> 1: Yes
#> 2: No
```

## The Key Parts of the Tidyverse Model of Data Science

Hadley proposes a model that nearly all data science projects approximate, described by the below illustration. This course module will mostly focus upon three of these concepts -- tidying, transforming, and visualizing. The other topics will be touched on in other course modules. A deeper dive is needed on all these topics for a well rounded data science professional, and it is again recommended to refer to [R for Data Science](https://r4ds.had.co.nz/). 

```{r echo = FALSE, out.width = "75%", fig.align='center'}
knitr::include_graphics("graphics/diagrams/data-science.png")
```

## Tidy Data

### What is Tidy Data?

You can represent the same underlying data in multiple ways. The example below shows the same data organised in four different ways. Each dataset shows the same values of four variables *country*, *year*, *population*, and *cases*, but each dataset organises the values in a different way.

```{r}
table1
table2
table3

# Spread across two tibbles
table4a  # cases
table4b  # population
```

These are all representations of the same underlying data, but they are not equally easy to use. One dataset, the tidy dataset, will be much easier to work with inside the tidyverse. 

There are three interrelated rules which make a dataset tidy:

1.  Each variable must have its own column.
1.  Each observation must have its own row.
1.  Each value must have its own cell.

The below illustration shows the rules visually: "Following three rules makes a dataset tidy: variables are in columns, observations are in rows, and values are in cells.

```{r tidy-structure, echo = FALSE, out.width = "100%"}
knitr::include_graphics("graphics/images/tidy-1.png")
```

These three rules are interrelated because it's impossible to only satisfy two of the three. That interrelationship leads to an even simpler set of practical instructions:

1.  Put each dataset in a tibble.
1.  Put each variable in a column.

In this example, only `table1` is tidy. It's the only representation where each column is a variable.

Why ensure that your data is tidy? There are two main advantages:

1.  There's a general advantage to picking one consistent way of storing
    data. If you have a consistent data structure, it's easier to learn the
    tools that work with it because they have an underlying uniformity.
    
1.  There's a specific advantage to placing variables in columns because
    it allows R's vectorised nature to shine. Most 
    built-in R functions work with vectors of values. That makes transforming 
    tidy data feel particularly natural.

`dplyr`, `ggplot2`, and all the other packages in the tidyverse are designed to work with tidy data.

### Tidying

#### Pivoting

The principles of tidy data seem so obvious that you might wonder if you'll ever encounter a dataset that isn't tidy. Unfortunately, however, most data that you will encounter will be untidy. There are two main reasons:

1.  Most people aren't familiar with the principles of tidy data, and it's hard
    to derive them yourself unless you spend a _lot_ of time working with data.
    
1.  Data is often organised to facilitate some use other than analysis. For 
    example, data is often organised to make entry as easy as possible.
    
This means for most real analyses, you'll need to do some tidying. The first step is always to figure out what the variables and observations are. Sometimes this is easy; other times you'll need to consult with the people who originally generated the data. 
The second step is to resolve one of two common problems:

1. One variable might be spread across multiple columns.

1. One observation might be scattered across multiple rows.

Typically a dataset will only suffer from one of these problems; it'll only suffer from both if you're really unlucky! To fix these problems, you'll need the two most important functions in tidyr: `pivot_longer()` and `pivot_wider()`.


#### Separating and uniting

So far you've learned how to tidy `table2` and `table4`, but not `table3`. `table3` has a different problem: we have one column (`rate`) that contains two variables (`cases` and `population`). To fix this problem, we'll need the `separate()` function. You'll also learn about the complement of `separate()`: `unite()`, which you use if a single variable is spread across multiple columns.

##### Separate

`separate()` pulls apart one column into multiple columns, by splitting wherever a separator character appears. Take `table3`:

```{r}
table3
```

The `rate` column contains both `cases` and `population` variables, and we need to split it into two variables. `separate()` takes the name of the column to separate, and the names of the columns to separate into, as shown in Figure \@ref(fig:tidy-separate) and the code below.

```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"))
```

```{r tidy-separate, echo = FALSE, out.width = "75%", fig.cap = "Separating `table3` makes it tidy"}
knitr::include_graphics("graphics/images/tidy-17.png")
```

By default, `separate()` will split values wherever it sees a non-alphanumeric character (i.e. a character that isn't a number or letter). For example, in the code above, `separate()` split the values of `rate` at the forward slash characters. If you wish to use a specific character to separate a column, you can pass the character to the `sep` argument of `separate()`. For example, we could rewrite the code above as:

```{r eval = FALSE}
table3 %>% 
  separate(rate, into = c("cases", "population"), sep = "/")
```

(Formally, `sep` is a regular expression, which you'll learn more about in [strings].)

Look carefully at the column types: you'll notice that `cases` and `population` are character columns. This is the default behaviour in `separate()`: it leaves the type of the column as is. Here, however, it's not very useful as those really are numbers. We can ask `separate()` to try and convert to better types using `convert = TRUE`:

```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE)
```

You can also pass a vector of integers to `sep`. `separate()` will interpret the integers as positions to split at. Positive values start at 1 on the far-left of the strings; negative value start at -1 on the far-right of the strings. When using integers to separate strings, the length of `sep` should be one less than the number of names in `into`. 

You can use this arrangement to separate the last two digits of each year. This make this data less tidy, but is useful in other cases, as you'll see in a little bit.

```{r}
table3 %>% 
  separate(year, into = c("century", "year"), sep = 2)
```

##### Unite

`unite()` is the inverse of `separate()`: it combines multiple columns into a single column. You'll need it much less frequently than `separate()`, but it's still a useful tool to have in your back pocket.

```{r tidy-unite, echo = FALSE, out.width = "75%", fig.cap = "Uniting `table5` makes it tidy"}
knitr::include_graphics("graphics/images/tidy-18.png")
```

We can use `unite()` to rejoin the *century* and *year* columns that we created in the last example. That data is saved as `tidyr::table5`. `unite()` takes a data frame, the name of the new variable to create, and a set of columns to combine, again specified in `dplyr::select()` style:

```{r}
table5 %>% 
  unite(new, century, year)
```

In this case we also need to use the `sep` argument. The default will place an underscore (`_`) between the values from different columns. Here we don't want any separator so we use `""`:

```{r}
table5 %>% 
  unite(new, century, year, sep = "")
```

### Transforming

Before we start an example, a note about **transforming**, to get us back to the Data Science framework we referred to above. Typically, after you tidy your data, there will be value that you add to that data by transforming it in some way.







### An Example: Part A

In submitting your interest for this course, you all generated some data that could use some tidying -- let's take a look at your Doodle responses below.  Some notes on the below code block:

- **The Pipe:** If you are not familiar with the `%>%` operator (known as 'the pipe operator'), meet your new best friend! It comes from the `magrittr` R package (part of the tidyverse) and gets rid of the need to nest multiple parantheses. Pass the result of one function directly into the first parameter of the next. 
- **A note on `pivot_*` functions:**  I (Bryan) did not realize prior to developing this course that `gather()` and `spread()` were no longer the preferred way of converting between longer and wider data formats, so I am learning this new preferred implementation along with you! Instead of `gather()`, we should be using `pivot_longer()`, and instead of `spread()` we should be using `pivot_wider()`. The old functions still work but they are no longer being actively improved. If the old functions mean nothing to you, then don't worry about this note! 
- **There are many ways to do this:** going from messy data to tidy data is not a straight line. You can use the functions below in a different order that can take more or less lines of code -- do this in the way that best makes sense to you and still gives you the result you want. Experiment using different lines to get to the same result!

```{r, message=FALSE, warning=FALSE}
library(tidyverse) #Loading the tidyverse
library(readxl) #For reading Excel files
library(janitor) #For cleaning up column names
library(forcats) #For implementing ordered categorical 
library(hms) #For working with times of day

raw_doodle = read_excel('data/r_doodle.xls')

raw_doodle

#Take a look at data in R studio viewer and in Excel. 
#Column names are weird, the information we want is several rows down from the top. 
#Luckily we can use skip some rows and rename columns to make them easier to manipulate

less_raw_doodle = read_excel('data/r_doodle.xls',skip = 3) %>% #Skipping three rows, we will need both weekday and time data from top two new rows
  clean_names() %>%#Cleaning names to make them easier to use, R likes names that don't have spaces, special characters, or leading numbers. 
  rename(x2 = august_2020, # We don't need to know that it is August 2020
         name = x1) #Name is going to be our primary identifier 
  
#Take a look at the newly read in dataset
less_raw_doodle

#We're going to break this data down into a couple of parts and join it back together 

#Time preferences
time_prefs = less_raw_doodle %>% 
  filter(!is.na(name)) %>% #Get only the rows with people's time preferences indicated
  pivot_longer(cols = starts_with('x'), #All columns except name
               names_to = 'key', #Old convention from gather
               values_to='value') #Old convention from gather

#Time block definitions
time_blocks = less_raw_doodle %>%
  slice(1:2) %>% #Extract first two rows
  select(-name) %>% #Do not need name column here
  pivot_longer(cols = everything(), #All columns
               names_to = 'key',
               values_to = 'value') %>%
  fill(value,.direction = 'down') %>%
  mutate(col_type = ifelse(str_detect(value,':'),'time','date')) %>%
  pivot_wider(id_cols = key,
              names_from=col_type,
              values_from=value)

#Join the split dataset back together
time_prefs_joined = time_prefs %>%
  left_join(time_blocks,by='key') %>%
  select(-key) %>% #Do not need this anymore
  filter(name!='Count') %>%
  mutate(value = case_when(
    value=='OK'~'Yes',
    value=='(OK)'~'Maybe',
    TRUE~'No'
  ),
  value = factor(value,ordered=TRUE,levels = c('Yes','Maybe','No')),
  weekday = str_sub(date,1,3),
  weekday = factor(weekday,ordered=TRUE,levels = c('Mon','Tue','Wed','Thu','Fri'))) %>%
  separate(time,into=c('from_time','to_time'),sep=' â€“ ') %>%
  mutate(from_time = strptime(from_time,format='%I:%M %p') %>%
           as.hms(),
         to_time = strptime(to_time,format='%I:%M %p') %>%
           as.hms()) %>%
  select(-date) %>%
  mutate(
    first_name = map_chr(name,function(name){
    (name %>%
      str_split(' ') %>%
      unlist())[1]}),
    last_name = map_chr(name,function(name){
    (name %>%
      str_split(' ') %>%
      unlist())[2]})
  ) %>%
  arrange(desc(last_name),desc(first_name),
          weekday,from_time,to_time) %>%
  mutate(name_factor = factor(name,ordered=TRUE,levels = unique(name)))

#Look how tidy this data is!!! This will make plotting much easier in next steps
time_prefs_joined

```

### Visualizing


### An Example: Part B

```{r, message=FALSE, warning=FALSE, fig.width=20, fig.height=8}
ggplot(time_prefs_joined)+
  geom_rect(aes(xmin=as.POSIXct(from_time),
                xmax=as.POSIXct(to_time),
                ymin = as.numeric(name_factor)-0.5,
                ymax = as.numeric(name_factor)+0.5,
                fill = value),
            alpha = 0.5)+
  facet_wrap(~weekday,nrow=1)+
  scale_y_continuous(breaks = 1:length(unique(time_prefs_joined$name_factor)),
                     labels = levels(time_prefs_joined$name_factor),
                     limits = c(0.5,(length(unique(time_prefs_joined$name_factor))+0.5)))+
  ggtitle('Doodle Results for Scheduling R Trainings')+
  xlab('Time of Day (PDT)')+ylab('Participant Name')+
  scale_x_datetime(date_labels = '%I %p',date_breaks = '1 hour')+
  theme(axis.text.x = element_text(angle = 45, hjust=1))

```



### Purrr

The [`purrr`](https://purrr.tidyverse.org/) package has been around for several years now, but with some recent updates across the tidyverse package, and my recent introduction via some [datacamp courses](https://learn.datacamp.com/skill-tracks/intermediate-tidyverse-toolbox?version=1), it has become a crucial part of my R programming toolbox that I would like to spend a moment on. 

### An Example: Part C

What if we want to clean this up a little bit -- we have a bunch of overlapping time blocks

```{r, message=FALSE, warning=FALSE, fig.width=20, fig.height=8}
time_prefs_clean = time_prefs_joined %>%
  select(name,name_factor,first_name,last_name,
         weekday,from_time,to_time,value) %>%
  nest(data = c(weekday,from_time,to_time,value)) %>%
  mutate(cleaned_time_blocks = map(data,function(data){
    
    grouped = data %>%
      mutate(group_num = 1)
    
    gn = 1
    
    for(i in 2:nrow(grouped)){
      if(grouped$value[i] != grouped$value[i-1] |
         grouped$weekday[i] != grouped$weekday[i-1]){
        gn = gn+1
        grouped$group_num[i] = gn
      }else{
        grouped$group_num[i] = gn
      }
    }
    
    clean = grouped %>%
      group_by(weekday,group_num,value) %>%
      summarise(min_time = as.hms(min(from_time)),
                max_time = as.hms(max(to_time)))

    return(clean)
  })) %>%
  select(-data) %>%
  unnest(cleaned_time_blocks)


ggplot(time_prefs_clean)+
  geom_rect(aes(xmin=as.POSIXct(min_time),
                xmax=as.POSIXct(max_time),
                ymin = as.numeric(name_factor)-0.5,
                ymax = as.numeric(name_factor)+0.5,
                fill = value),
            color='white',size=1)+
  facet_wrap(~weekday,nrow=1)+
  scale_y_continuous(breaks = 1:length(unique(time_prefs_joined$name_factor)),
                     labels = levels(time_prefs_joined$name_factor),
                     limits = c(0.5,(length(unique(time_prefs_joined$name_factor))+0.5)))+
  ggtitle('Cleaner Doodle Results for Scheduling R Trainings')+
  xlab('Time of Day (PDT)')+ylab('Participant Name')+
  scale_x_datetime(date_labels = '%I %p',date_breaks = '1 hour')+
  theme(axis.text.x = element_text(angle = 45, hjust=1))

```

Viola! That is it for this lesson -- we have spent some time on tidying, transforming, and visualizing. Of course your learning doesnt end here -- I have included a number of resources for review below that will help you delve deeper into and master these topics. 

### Related DataCamp Courses

- [Tidyverse Fundamentals course track (5 courses, 20 hours)](https://learn.datacamp.com/skill-tracks/tidyverse-fundamentals)
- [Intermediate Tidyverse Toolbox course track (4 courses, 16 hours)](https://learn.datacamp.com/skill-tracks/intermediate-tidyverse-toolbox?version=1)

### Further Reading 

- [R for Data Science](https://r4ds.had.co.nz/), by Garrett Grolemund and Hadley Wickham. As mentioned above, some of the content for this module is copied directly from that book. 
  

